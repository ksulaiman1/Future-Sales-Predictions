{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129437ee-20ed-4bca-a99c-d32f69691364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import collections\n",
    "import contextlib\n",
    "import sys\n",
    "import wave\n",
    "import webrtcvad\n",
    "import librosa\n",
    "import soundfile\n",
    "\n",
    "\n",
    "import concurrent.futures\n",
    "from wvmos import get_wvmos\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0276eadc-4882-4d56-8ab0-8c872975e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "females = pd.read_excel('females.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad1b744-b8d5-45b0-a91c-c87a14168868",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = females.client_id.value_counts().iloc[:20].index.tolist()\n",
    "twenty_females= females[females.client_id.isin(client_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1f75cb-c09f-4fd7-8256-6f2771d610c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9797/2113391793.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twenty_females.sort_values(by=['path'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "twenty_females.sort_values(by=['path'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e6512ea-4e21-4821-b064-00af97f00849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9797/1542461241.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  six_females = twenty_females[\n"
     ]
    }
   ],
   "source": [
    "six_females = twenty_females[\n",
    "    (females.client_id == '77844f4f66a5cd12f1aa1dd9f236547e9d8dc724641c17aeba50b2dd7ae7b457af95d55838392288c6ed2b7881a617c7bf3f51edda9dfe8c3a882c0669baa1c7') |\n",
    "    (females.client_id == '66858b5ce4429ee1297e082789724acb02c7c3d38e543b03815604906fa731232f78b0a5b822b036f3d856b27f3815e1837349b842f8aa6e0be7ab68940e39be') |\n",
    "    (females.client_id == 'a59598f0a310679014e8663eeed32c7408fa0b0922e9e3f4eb4a759eb199342345753267b9c0cc4116d838f73c7f4b49350b4bd646caee4ac50935b60186d9f3') |\n",
    "    (females.client_id == '6e09ff9cc1f149df26e8db256a211d367bced4288641e22c9dd82fbae9ad823f49058c132ab42e9d942ed3d3e24ac64b96bbe7419bb43d4a40c3ba3c1c7223b2') |\n",
    "    (females.client_id == 'dec0c7bd1c3b6b23e33c8a289e9b37541ae9ec7a57697a72f275ee010799d658ed122c00988fd1f29baa0cca9425962bac63585808549d3fa638fb1fb64b2a96') |\n",
    "    (females.client_id == 'a1313c5f1f30851ca0eb76c4ce9080b2ddc359b0111d1e8a9de1cd37f15e954b3bff006047b54e726ca7f8c78c7b8527a3e62d47c9f8b71f869a9f4bbb1dbbf1')\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f447908-f21a-4f34-859e-1aaebf078d5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9797/4044183189.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  six_females['duration_seconds'] = six_females['duration[ms]']/1000\n"
     ]
    }
   ],
   "source": [
    "six_females['duration_seconds'] = six_females['duration[ms]']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0119a626-ce07-4e67-a1ea-6834c89bfab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9797/3817877466.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  six_females['path'] = six_females['path'].apply(lambda x: x.replace('.mp3', '.wav'))\n"
     ]
    }
   ],
   "source": [
    "six_females['path'] = six_females['path'].apply(lambda x: x.replace('.mp3', '.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd13efab-5584-44d1-92c4-bf420c15c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir 'six_females_wavs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ad8f394-0198-4d9c-bb65-8ec91fdb67dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6cf515cd7d451e96b62c6f26ba7735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for file_name in tqdm(six_females.path):\n",
    "    source = 'female_wavs/' + file_name\n",
    "    destination = 'six_females_wavs/' + file_name\n",
    "    # copy only files\n",
    "    if os.path.isfile(source):\n",
    "        shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e91769-9911-4671-b92e-3ccf098bbf45",
   "metadata": {},
   "source": [
    "## Voice Activity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c43a6e-04de-4b90-9573-614d4f960d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave(path):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        sample_rate = 32000  # We will pretend it's sampled at 16k\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "\n",
    "\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    \"\"\"Writes a .wav file.\n",
    "    Takes path, PCM audio data, and sample rate.\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    \"\"\"Generates audio frames from PCM audio data.\n",
    "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "    the sample rate.\n",
    "    Yields Frames of the requested duration.\n",
    "    \"\"\"\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms,\n",
    "                  padding_duration_ms, vad, frames):\n",
    "    \"\"\"Filters out non-voiced audio frames.\n",
    "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
    "    the voiced audio.\n",
    "    Uses a padded, sliding window algorithm over the audio frames.\n",
    "    When more than 90% of the frames in the window are voiced (as\n",
    "    reported by the VAD), the collector triggers and begins yielding\n",
    "    audio frames. Then the collector waits until 90% of the frames in\n",
    "    the window are unvoiced to detrigger.\n",
    "    The window is padded at the front and back to provide a small\n",
    "    amount of silence or the beginnings/endings of speech around the\n",
    "    voiced frames.\n",
    "    Arguments:\n",
    "    sample_rate - The audio sample rate, in Hz.\n",
    "    frame_duration_ms - The frame duration in milliseconds.\n",
    "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
    "    vad - An instance of webrtcvad.Vad.\n",
    "    frames - a source of audio frames (sequence or generator).\n",
    "    Returns: A generator that yields PCM audio data.\n",
    "    \"\"\"\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    # We use a deque for our sliding window/ring buffer.\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
    "    # NOTTRIGGERED state.\n",
    "    triggered = False\n",
    "\n",
    "    voiced_frames = []\n",
    "    for frame in frames:\n",
    "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
    "\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
    "            # the ring buffer are voiced frames, then enter the\n",
    "            # TRIGGERED state.\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                # We want to yield all the audio we see from now until\n",
    "                # we are NOTTRIGGERED, but we have to start with the\n",
    "                # audio that's already in the ring buffer.\n",
    "                for f, s in ring_buffer:\n",
    "                    voiced_frames.append(f)\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            # We're in the TRIGGERED state, so collect the audio data\n",
    "            # and add it to the ring buffer.\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            # If more than 90% of the frames in the ring buffer are\n",
    "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
    "            # audio we've collected.\n",
    "            if num_unvoiced > 0.5 * ring_buffer.maxlen:\n",
    "                triggered = False\n",
    "                yield b''.join([f.bytes for f in voiced_frames])\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "\n",
    "    # If we have any leftover voiced audio when we run out of input,\n",
    "    # yield it.\n",
    "    if voiced_frames:\n",
    "        yield b''.join([f.bytes for f in voiced_frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22529bc8-288e-4cc2-88e8-1fc99a76eb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘filtered_six_wavs/’: File exists\n",
      "mkdir: cannot create directory ‘new_six_wavs/’: File exists\n"
     ]
    }
   ],
   "source": [
    "wav_32k_dir = 'six_females_wavs/'\n",
    "filtered_tmp_dir = 'filtered_six_wavs/'\n",
    "final_wav_dir = 'new_six_wavs/'\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "!mkdir 'filtered_six_wavs/'\n",
    "!mkdir 'new_six_wavs/'\n",
    "\n",
    "bad_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb3730ed-3cdf-4b92-b4bf-810b28472062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ee678154b445328eee9f738461ff11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clip_wav_to_speech_and_save(wav_path):\n",
    "    filename = os.path.basename(wav_path)\n",
    "    if not os.path.exists(os.path.join(final_wav_dir, filename)):\n",
    "        audio, sample_rate = read_wave(\n",
    "            os.path.join(wav_32k_dir, filename))\n",
    "        vad = webrtcvad.Vad(3)\n",
    "        frames = frame_generator(30, audio, sample_rate)\n",
    "        frames = list(frames)\n",
    "        segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
    "        speech = b''.join(list(segments))\n",
    "        # Likely to be a problem if less than 1s of speech\n",
    "        if len(speech) < sample_rate * 2:\n",
    "            bad_files.append(wav_path)        \n",
    "        else:\n",
    "            write_wave(\n",
    "                os.path.join(filtered_tmp_dir, filename),\n",
    "                speech, sample_rate)\n",
    "            # Resample to SAMPLE_RATE\n",
    "            wav, _ = librosa.load(\n",
    "                os.path.join(filtered_tmp_dir, filename),\n",
    "                sr=SAMPLE_RATE)\n",
    "            soundfile.write(\n",
    "                os.path.join(final_wav_dir, filename),\n",
    "                wav, SAMPLE_RATE)  # Trim a little extra from the end  \n",
    "for wav_path in tqdm(six_females.path):\n",
    "    clip_wav_to_speech_and_save(wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ca99472-df20-46c5-8d38-72ded4c27b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['common_voice_sw_30129692.wav',\n",
       " 'common_voice_sw_31268635.wav',\n",
       " 'common_voice_sw_31268795.wav',\n",
       " 'common_voice_sw_31270475.wav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1341516-12c3-4da8-9f72-819a2dd03ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove 4 files without speech, new total: 18024.\n"
     ]
    }
   ],
   "source": [
    "six_females = six_females[~six_females.path.isin(bad_files)]\n",
    "\n",
    "print(f'Remove {len(bad_files)} files without speech, new total: {len(six_females)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1d6e7f0-5665-4528-baa5-9330cd4f5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_females.to_csv('new_six.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "018b4a09-40d1-47bc-9b60-c29b9dda2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_females.sort_values(by=['path'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df325aac-7b6e-4bb5-b841-720686999608",
   "metadata": {},
   "source": [
    "## Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b05b07d-e100-4461-9aa5-8f0e81afe7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘new_six_denoised/’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"new_six_denoised/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "330dc074-439d-4762-b7f7-18768ed16433",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_audio_dir = \"new_six_wavs/\"\n",
    "denoised_audio_dir = \"new_six_denoised/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "850464ef-8646-41c2-ac58-70b7a111ed30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c764d8da4f4eadb66da69bbfd32473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load denoising model\n",
    "model = pretrained.dns64().cuda()\n",
    "\n",
    "# Loop through each audio file in the noisy audio directory\n",
    "for audio_file in tqdm(six_females.path):\n",
    "    # Load noisy audio\n",
    "    noisy_audio, sr = torchaudio.load(os.path.join(noisy_audio_dir, audio_file))\n",
    "\n",
    "    # Denoise audio\n",
    "    denoised_audio = convert_audio(noisy_audio.cuda(), sr, model.sample_rate, model.chin)\n",
    "    with torch.no_grad():\n",
    "        denoised_audio = model(denoised_audio[None])[0]\n",
    "\n",
    "    # Save denoised audio\n",
    "    denoised_audio_path = os.path.join(denoised_audio_dir, audio_file)\n",
    "    torchaudio.save(denoised_audio_path, denoised_audio.cpu(), model.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4659c079-a8a1-48c1-a50b-a802e450147f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b7cf379ee949e58518d395fc25bb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the source directory\n",
    "src_dir = \"new_six_denoised/\"\n",
    "\n",
    "# Set the target sample rate\n",
    "target_sr = 22050\n",
    "\n",
    "for filename in tqdm(os.listdir(src_dir)):\n",
    "    # Check if the file is a .wav file\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Load the audio file\n",
    "        filepath = os.path.join(src_dir, filename)\n",
    "        audio = AudioSegment.from_wav(filepath)\n",
    "\n",
    "        # Change the sample rate and save back to the same location\n",
    "        audio = audio.set_frame_rate(target_sr)\n",
    "        audio.export(filepath, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfcbbaa-3866-4da0-9441-c85b3921eb10",
   "metadata": {},
   "source": [
    "## WV-MOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dab42e27-d25a-453d-b27b-071af20ef865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-ws/miniconda3/envs/sula/lib/python3.9/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/home/lab-ws/miniconda3/envs/sula/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/home/lab-ws/miniconda3/envs/sula/lib/python3.9/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = get_wvmos(cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "076059b4-1b03-4c7d-81eb-c539272d3adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18024/18024 [04:16<00:00, 70.26it/s]\n"
     ]
    }
   ],
   "source": [
    "mos= model.calculate_dir('new_six_denoised/', mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30dc11f0-263f-4990-9628-1a1034fa6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_females['wvmos'] = mos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66d3721b-0770-4538-abf4-c31e8e2c0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "six_females.to_csv('six_mos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4730a930-7565-433f-bb32-e0908c2519b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "six_mos3 = six_females[six_females.wvmos>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "382cbb0e-14cb-4d24-83dd-02caa23c135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir 'six_mos3_wavs/wavs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14e75295-48b5-4ded-b1b6-5efea9a853d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a60920b2bed4dd4b00394adc1ee27a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for file_name in tqdm(six_mos3.path):\n",
    "    source = 'new_six_denoised/' + file_name\n",
    "    destination = 'six_mos3_wavs/wavs/' + file_name\n",
    "    # copy only files\n",
    "    if os.path.isfile(source):\n",
    "        shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105082af-bace-4a70-981d-27fc8e90be71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc8193b0-5855-445c-afd4-4afe4841f2a1",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10e0a7e6-786b-46f7-ac53-a9ff7a2bfb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9797/1545359344.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  six_mos3['cleaned_sentence'] = clean_sentences(six_mos3['sentence'])\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def clean_sentences(sentences):\n",
    "    cleaned = []\n",
    "    for sentence in sentences:\n",
    "        cleaned_sentence = sentence.strip()\n",
    "        cleaned.append(cleaned_sentence)\n",
    "    return cleaned\n",
    "\n",
    "six_mos3['cleaned_sentence'] = clean_sentences(six_mos3['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0df0923-eb69-49e3-abd0-76b7fffd0912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9797/1773889350.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  six_mos3['replaced_sentence'] = six_mos3.cleaned_sentence.apply(lambda  x: replace_characters(x, replacements))\n"
     ]
    }
   ],
   "source": [
    "replacements = {\n",
    "    '‘':'\\'',\n",
    "    '’':'\\'',\n",
    "    '“':'\\'',\n",
    "    '”':'\\'',\n",
    "    '\"':'\\'',\n",
    "    '…':' ',\n",
    "    '`':'',\n",
    "}\n",
    "\n",
    "def replace_characters(s, replacements):\n",
    "    for c in replacements.keys():\n",
    "        s = s.replace(c, replacements[c])\n",
    "    return s\n",
    "\n",
    "    # Use the translate() method to perform the replacements\n",
    "#     return s.translate(translation_table)\n",
    "six_mos3['replaced_sentence'] = six_mos3.cleaned_sentence.apply(lambda  x: replace_characters(x, replacements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cafa85f-9010-4477-a809-b22a937c2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_LJSpeech_line(df):\n",
    "    lines = []\n",
    "    for file, clean in zip(df.path, df.replaced_sentence):\n",
    "        text = f'{file}|{clean}|{clean}'\n",
    "        lines.append(text)\n",
    "        with open('six_mos3_wavs/metadata.csv', 'w') as f:\n",
    "            f.write(os.linesep.join(lines))\n",
    "            \n",
    "generate_LJSpeech_line(six_mos3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b572c-893a-40f3-b346-f3e212ef62ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ec9f0-0384-46f9-b826-10484df0d06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
